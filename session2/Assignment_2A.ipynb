{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Session2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nJ7YEw_vyjG",
        "colab_type": "text"
      },
      "source": [
        "# **Not an ideal network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGWv5hBhv2jf",
        "colab_type": "code",
        "outputId": "4ae0bb6f-2e2d-460d-fe7e-5895ae568951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gbv8D5QE7vUD",
        "colab_type": "text"
      },
      "source": [
        "#### Import all Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnMlDJQKv4VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Convolution2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bo8NJnj719W",
        "colab_type": "text"
      },
      "source": [
        "#### Load mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CdSu2lMwB9s",
        "colab_type": "code",
        "outputId": "e50ce456-0774-48fd-837c-1bf1792ceea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1hGaDh77_CZ",
        "colab_type": "text"
      },
      "source": [
        "#### Visualise single image of the train data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLaDf0-rwCmj",
        "colab_type": "code",
        "outputId": "25607444-7019-42e3-86da-b315becfd559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4b11c91d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADuBJREFUeJzt3X2wVPV9x/HPl8sVlISGJ2+uQEKI\nWMvDCO0VWkMTrTFjHCsmdjRM0yHTTEinkDYOk9SHmcRMZjq202ixzUOvDRFNgnZ8iDRxYixjxmS0\nDheiIEEeQlChPKg4giJw7+XbP+7BudF7frvsnt2z+H2/Zu7c3fPds+fLwoez5/x2z8/cXQDiGVZ2\nAwDKQfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwQ1vJkbO81G+EiNauYmgVCO6HUd86NWzWPr\nCr+ZXSppuaQ2Sf/p7jenHj9SozTPLq5nkwASnvQ1VT+25rf9ZtYm6ZuSPi5puqSFZja91ucD0Fz1\nHPPPlbTd3Xe4+zFJd0taUExbABqtnvBPlPTCoPu7smW/w8wWm1mPmfX06mgdmwNQpIaf7Xf3bnfv\ncveudo1o9OYAVKme8O+WNHnQ/UnZMgCngHrCv1bSNDP7gJmdJulTklYX0xaARqt5qM/d+8xsqaSH\nNTDUt8LdNxXWGYCGqmuc390fkvRQQb0AaCI+3gsERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjC\nDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAo\nwg8ERfiBoAg/EBThB4Ii/EBQdc3Sa2Y7JR2S1C+pz927imgKp462cWOTdfu90bm15686K7nukfGe\nrJ/9taeT9eOHDyfr0dUV/sxF7v5SAc8DoIl42w8EVW/4XdLPzGydmS0uoiEAzVHv2/757r7bzM6U\n9IiZPevujw1+QPafwmJJGqkz6twcgKLUted3993Z7/2SHpA0d4jHdLt7l7t3tWtEPZsDUKCaw29m\no8zs3SduS/qYpGeKagxAY9Xztr9D0gNmduJ5fujuPy2kKwANV3P43X2HpPMK7AUlGDbz3GR92/Wn\nJ+t/PevxZH3ZuIdPuqdq/UHH3yTr0z6zrmHbfidgqA8IivADQRF+ICjCDwRF+IGgCD8QVBHf6kPJ\n7PxZubXt17Yl1/35/H9P1ie0pT+VOazC/uMnh8fk1nYcPTO57pIxW5L1uz58e7L+9fMX5dZ87cbk\nuhGw5weCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnbwFtEyYk61uXT0zW//uCb+XWpra3V9h6fVdX\n+t7Bycn6j66an1s7PiLd25Ifp8f5u0b0J+tvdOR/HXlkcs0Y2PMDQRF+ICjCDwRF+IGgCD8QFOEH\ngiL8QFCM87eA3Z+elqxv+sjyCs9QaSy/dt+vNI5/5QXJev+Wrbk1mzOjpp5QDPb8QFCEHwiK8ANB\nEX4gKMIPBEX4gaAIPxBUxXF+M1sh6XJJ+919ZrZsrKR7JE2RtFPS1e7+SuPafGebeMXOhj33va+9\nN1m/ZevFyXrHlz1Z79+y7aR7OuGVWaNrXhf1q2bPf4ekS9+y7DpJa9x9mqQ12X0Ap5CK4Xf3xyQd\neMviBZJWZrdXSrqy4L4ANFitx/wd7r4nu71XUkdB/QBokrpP+Lm7S8o9MDSzxWbWY2Y9vTpa7+YA\nFKTW8O8zs05Jyn7vz3ugu3e7e5e7d7XXebFIAMWpNfyrJZ2YAnWRpAeLaQdAs1QMv5mtkvSEpN83\ns11m9llJN0u6xMy2Sfpodh/AKaTiOL+7L8wppQeIUb3PpQ+Hpi/5QrI++ZH869eP2rQ3ue745/K/\nby9J6Svj1+dwhzXw2VEJn/ADgiL8QFCEHwiK8ANBEX4gKMIPBMWlu1tA//bfJutnX5uup/TVvGbj\n9Z5/qOwWQmPPDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc4f3PNfSU+x3XdG+tLdqvSt3MTqn5z2\nRIWV05buujBZP/2n63NrFf5UIbDnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgGOc/BbSNTk9lfWTu\ntNxa+/X7kutuOPffaurpzee3tmS912u/+Pejb5yRrO9a/L5k3fs217ztCNjzA0ERfiAowg8ERfiB\noAg/EBThB4Ii/EBQFcf5zWyFpMsl7Xf3mdmymyR9TtKL2cNucPeHGtXkqc5GpKfgPvaRWcn6td+6\nK1m/6PQ1ubV9/UeT6z76xphk/StbFyTrq2bckayfNTz9Z08ZOaw3Wd9x9XuS9albRubWjh85UlNP\n7yTV7PnvkHTpEMtvdffZ2Q/BB04xFcPv7o9JOtCEXgA0UT3H/EvNbIOZrTCz9HtHAC2n1vB/W9IH\nJc2WtEfSN/IeaGaLzazHzHp6lT7+BNA8NYXf3fe5e7+7H5d0u6S5icd2u3uXu3e1q/aTPwCKVVP4\nzaxz0N1PSHqmmHYANEs1Q32rJF0oabyZ7ZL0VUkXmtlsDVwBeaekzzewRwANYO7Nu4L5aBvr8+zi\npm2vWYaNzB9PlqSXr5mTrP/iH2+ra/szVn0htzbp0fT36Uf8ZG2yPrzzvcn6hx7+bbK+bFx5bwr/\n5Ot/l1vruPPp5LrHDx8uup2meNLX6KAfqDSbgiQ+4QeERfiBoAg/EBThB4Ii/EBQhB8IiqG+KqW+\nlrvl1vOS6z674Jt1bXvBliuT9WEL87/62r9vf3Ld4ZMnJevnrX4+Wf/amb9K1l89nv/V2Xn3LUuu\n23luuvc1s+5J1lOu2X55sv7SbVOS9ZEvp79uXEnbz/OnD68HQ30AKiL8QFCEHwiK8ANBEX4gKMIP\nBEX4gaCYojtjw9MvxZZ/zR/Lf/aK9Dj+rr705cuu+I8vJ+tTVvwmWe9LjOX3fvSPkuvO/Kf0OP1X\nz1yXrH/v4PuT9btu/PPc2tn3/29y3bbx45L1Cy/J/yqzJL1+zau5tQfm3J5cd9Jt9V116sevp3vv\nPmdqXc9fBPb8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU3+fP7Lr+gmR9/dLlubX/qzCOf9XNX0rW\nO3+Uvvz1gYumJOv+6Zdya/fOvCO57oS29Hj2jLvTY+nndOdvW5L6t2xP1suy/2/Tf98df/FcfRtY\nlp4+3H+1qb7nz8H3+QFURPiBoAg/EBThB4Ii/EBQhB8IivADQVUc5zezyZLulNQhySV1u/tyMxsr\n6R5JUyTtlHS1u7+Seq5WHue/ccdTyfq8EfnXaT/Qnx7n/84r85L1iaclXzYtGl3nmHPCjB/mT2Mt\nSWdfn57C2/v6imwHdSp6nL9P0jJ3ny7pjyUtMbPpkq6TtMbdp0lak90HcIqoGH533+Pu67PbhyRt\nljRR0gJJK7OHrZSUnlYGQEs5qWN+M5siaY6kJyV1uPuerLRXA4cFAE4RVYffzN4l6T5JX3T3g4Nr\nPnDiYMiTB2a22Mx6zKynV+ljYwDNU1X4zaxdA8H/gbvfny3eZ2adWb1T0pBXkXT3bnfvcveudtV3\nUUQAxakYfjMzSd+VtNndbxlUWi1pUXZ7kaQHi28PQKNUM9Q3X9IvJG2UdDxbfIMGjvv/S9L7JD2n\ngaG+A6nnauWhvj/dkD+VtCR9adzGJnXydpc/+8lk/fkn8qfZnnpv/uWrJck3pb9y673HknW0lpMZ\n6qt43X53/6WkvCdrzSQDqIhP+AFBEX4gKMIPBEX4gaAIPxAU4QeCYoruzOMXnZWsz/vLP8utvXpe\neix8+Ivtyfo539mdXn9v/hTckjTlyAu5teO5FUTHnh8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKc\nP9P/cvJSBOq47fH8Wp3b5uLXKAN7fiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF\n+IGgCD8QFOEHgiL8QFCEHwiqYvjNbLKZPWpmvzazTWb299nym8xst5k9lf1c1vh2ARSlmot59Ela\n5u7rzezdktaZ2SNZ7VZ3/5fGtQegUSqG3933SNqT3T5kZpslTWx0YwAa66SO+c1siqQ5kp7MFi01\nsw1mtsLMxuSss9jMesysp1dH62oWQHGqDr+ZvUvSfZK+6O4HJX1b0gclzdbAO4NvDLWeu3e7e5e7\nd7VrRAEtAyhCVeE3s3YNBP8H7n6/JLn7Pnfvd/fjkm6XNLdxbQIoWjVn+03SdyVtdvdbBi3vHPSw\nT0h6pvj2ADRKNWf7PyTpryRtNLOnsmU3SFpoZrMluaSdkj7fkA4BNEQ1Z/t/KcmGKD1UfDsAmoVP\n+AFBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Iyd2/exsxe\nlPTcoEXjJb3UtAZOTqv21qp9SfRWqyJ7e7+7T6jmgU0N/9s2btbj7l2lNZDQqr21al8SvdWqrN54\n2w8ERfiBoMoOf3fJ209p1d5atS+J3mpVSm+lHvMDKE/Ze34AJSkl/GZ2qZltMbPtZnZdGT3kMbOd\nZrYxm3m4p+ReVpjZfjN7ZtCysWb2iJlty34POU1aSb21xMzNiZmlS33tWm3G66a/7TezNklbJV0i\naZektZIWuvuvm9pIDjPbKanL3UsfEzazD0t6TdKd7j4zW/bPkg64+83Zf5xj3P0fWqS3myS9VvbM\nzdmEMp2DZ5aWdKWkz6jE1y7R19Uq4XUrY88/V9J2d9/h7sck3S1pQQl9tDx3f0zSgbcsXiBpZXZ7\npQb+8TRdTm8twd33uPv67PYhSSdmli71tUv0VYoywj9R0guD7u9Sa0357ZJ+ZmbrzGxx2c0MoSOb\nNl2S9krqKLOZIVScubmZ3jKzdMu8drXMeF00Tvi93Xx3/0NJH5e0JHt725J84JitlYZrqpq5uVmG\nmFn6TWW+drXOeF20MsK/W9LkQfcnZctagrvvzn7vl/SAWm/24X0nJknNfu8vuZ83tdLMzUPNLK0W\neO1aacbrMsK/VtI0M/uAmZ0m6VOSVpfQx9uY2ajsRIzMbJSkj6n1Zh9eLWlRdnuRpAdL7OV3tMrM\nzXkzS6vk167lZrx296b/SLpMA2f8fyPpxjJ6yOlrqqSns59NZfcmaZUG3gb2auDcyGcljZO0RtI2\nSf8jaWwL9XaXpI2SNmggaJ0l9TZfA2/pN0h6Kvu5rOzXLtFXKa8bn/ADguKEHxAU4QeCIvxAUIQf\nCIrwA0ERfiAowg8ERfiBoP4ffm+Zwo6qf/gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lucnrcQz8Kgc",
        "colab_type": "text"
      },
      "source": [
        "#### Reshape the images 28X28X1 which goes as a input image for the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erb11jNwwFwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PolKe62i81Mj",
        "colab_type": "text"
      },
      "source": [
        "#### Standardise the pixel values which are between 0 to 255 and resultant values are between 0 to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLK4YDoRwHet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAlhNSfR9OHi",
        "colab_type": "text"
      },
      "source": [
        "#### Target classes of corresponding images. Values are between 0 to 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKLOmhlwJQl",
        "colab_type": "code",
        "outputId": "137b9aec-5040-408d-ebea-7dd31ef4f72e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H7sMdiE9j_t",
        "colab_type": "text"
      },
      "source": [
        "#### Convert the target classes to one-hot vector of size 10 i,e. target class's positional value will become 1 and rest all positions are filled with 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YusMJguiwKsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxc99AswMW0",
        "colab_type": "code",
        "outputId": "ceebf019-852a-47b0-dda9-4afb8c1f1e07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irTVUE47wNwr",
        "colab_type": "code",
        "outputId": "1d21e863-a7f8-4484-a394-3cea471ee93a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        }
      },
      "source": [
        "from keras.layers import Activation, MaxPooling2D\n",
        "\n",
        "model = Sequential() \n",
        "#Receptive field becomes: 3X3\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "\n",
        "#Receptive field becomes: 5X5\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "\n",
        "#Receptive field becomes: 7X7\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "\n",
        "#Receptive field becomes: 14X14\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Receptive field becomes: 16X16\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "\n",
        "##Receptive field becomes: 18X18\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "\n",
        "##Receptive field becomes: 20X20\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu'))\n",
        "\n",
        "##Receptive field becomes: 22X22\n",
        "model.add(Convolution2D(2048, 3, 3, activation='relu'))\n",
        "\n",
        "##Receptive field becomes: 24X24\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          184330    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,348,362\n",
            "Trainable params: 25,348,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZOpRb6yG7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O248wVQyMft",
        "colab_type": "code",
        "outputId": "e2a17b7c-5001-4552-a72e-d4bde0b762c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 120s 2ms/step - loss: 2.3030 - acc: 0.0988\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 2.3026 - acc: 0.0987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f70f6e75e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sst4KneiyOL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfJiXOKsyj4y",
        "colab_type": "code",
        "outputId": "8f551856-10f1-4c8d-c007-3a7ce9df965d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.3025851249694824, 0.098]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwLSXt7nyn_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKKoOKwyppN",
        "colab_type": "code",
        "outputId": "f93d2d2f-be8c-4f84-f99a-62c4c114e0e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(y_pred[:9])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6Ox0ZzmcJMU",
        "colab_type": "text"
      },
      "source": [
        "#### As we observe from the images..\n",
        "\n",
        "1. The dataset has images of hand written digits. Each image has only one digit in it.\n",
        "\n",
        "2. This problem statement is not so complex. As per my understanding very simple network with less than 15k parameters    will give more than 90% accuracy. \n",
        "\n",
        "3. When we observe the network architecture in current notebook we observe that in each layer we are doubling the channels. Which will add too many parameters to the network. Because of too many parameters the network will bulkier and takes lots of time to train\n",
        "\n",
        "4. As the given images does not contain complex objects in it only some basic channels like edges,gradients are suffient but in this architecture we are adding too many channels which will cause unnecessary overload and also will confuse the network with too many channels.\n",
        "\n",
        "5. One more important thing is we are using 3x3 kernal to reduce the number channels which is not a good practice.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgSO-Mcfcghx",
        "colab_type": "text"
      },
      "source": [
        "#### Slight improvisation on previous network.\n",
        "\n",
        "I just added a 1X1 kernel to reduce the number of channels followed by 3X3 convolution which shoot up the accuracy.  Still we can work on to reduce number of channels from the layers which will make the network much more faster and efficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ6EEn87AoIg",
        "colab_type": "code",
        "outputId": "25596af2-e50d-454b-89d0-4db241d269ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        }
      },
      "source": [
        "from keras.layers import Activation, MaxPooling2D\n",
        "\n",
        "model = Sequential() \n",
        "#Receptive field becomes: 3X3\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "\n",
        "#Receptive field becomes: 5X5\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "\n",
        "#Receptive field becomes: 7X7\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "\n",
        "#Receptive field becomes: 14X14\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Receptive field becomes: 16X16\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "\n",
        "##Receptive field becomes: 18X18\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "\n",
        "##Receptive field becomes: 20X20\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu'))\n",
        "\n",
        "##Receptive field becomes: 22X22\n",
        "model.add(Convolution2D(2048, 3, 3, activation='relu'))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "##Receptive field becomes: 24X24\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 3, 3, 10)          20490     \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,185,432\n",
            "Trainable params: 25,185,432\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ38xHiybF1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8iGO7HobLn1",
        "colab_type": "code",
        "outputId": "e9393e2c-437d-4988-ccfe-6e72bc91d028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 121s 2ms/step - loss: 0.2915 - acc: 0.9045\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0666 - acc: 0.9814\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0524 - acc: 0.9853\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0433 - acc: 0.9879\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0335 - acc: 0.9907\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0327 - acc: 0.9910\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0296 - acc: 0.9922\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0254 - acc: 0.9926\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0209 - acc: 0.9943\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0255 - acc: 0.9929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4b0e827f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhJ-tOs9b4Xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fQPIoEpfwZL",
        "colab_type": "code",
        "outputId": "0e8c7753-2da1-4db8-97ad-cdaacc0eb165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.04424734497017498, 0.9888]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcqADQ9UgU7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}